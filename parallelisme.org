Les architectures modernes sont capables de faire plusieurs opérations
simultanément de manière quasi-transparente pour le programmeur:
- avec l'exécution out-of-order des instructions du processeur
- en exécutant plusieurs flots d'instruction simultanément pour
  recouvrir les temps d'accès à la RAM ("l'hyperthreading" pour Intel)
- en faisant des calculs vectoriels (là les compilateurs ont encore
  des progrès à faire)

Ce parallélisme automatique est loin de refleter le potentiel
parallèle de la plupart des applications.

Les compilateurs ne sont pas capable de l'extraire de manière
automatique, même pour des langages "simples" comme Fortran.

Donc le programmeur doit faire le travail d'expliquer au compilateur
et au matériel comment faire plusieurs choses à la fois.

* Comment lancer plusieurs activités partageant la même mémoire

  Dans la plupart des languages modernes, faire plusieurs choses à la
  fois dans le même espace de mémoire, i.e. dans le même processus, est
  souvent relativement facile à faire:
  - parce que c'est prévu dans le language: Go, Cilk, OpenMP, Ruby
  - parce que c'est prévu dans la bibliothèque standard du langage: C,
    C++, D, Ada, Java, Perl, Python

  Cela n'a pas toujours été évident: il a fallu attendre la norme
  C-11, 40 ans après le début du langage, pour avoir des threads en C.

  Python et ruby, en collant aux opérateurs des langages compilés,
  atteignent pour l'instant un parallélisme limité. Perl, qui a pris
  un autre chemin, permet un parallélisme performant au prix d'une
  gymnastique intellectuelle différente des gymnastiques classiques.

  Les codes suivants réalisent un "hello world" parallèle.

** Démarrer des threads en C
*** TODO Attendre la version de la glibc avec threads.h

** Démarrer des POSIX threads en C
   En pratique, la bibliothèque de threads implantée sous Linux est la
   bibliothèque POSIX. C'est elle qui est utilisé par la bibliothèque
   de C et de la quasi-totalité des autres languages.

#+INCLUDE: Codeparallelisme/startC99.c src C

ce qui après compilation et exécution

#+BEGIN_SRC sh :exports code
gcc -Wall -std=gnu99 Codeparallelisme/startC99.c -o bin/startC99 -lpthread
bin/startC99
#+END_SRC

produit l'affichage suivant (systématique)

: hello  world! de 0
: hello  world! de 1

** Démarrer des threads en C++

#+INCLUDE: Codeparallelisme/startCpp.cpp src C++

La compilation et l'exécution sont intéressantes. Avec les iostream,
on a parfois des mélanges intéressants. Pour observer ce mélange en C
avec printf, il faudrait probablement des sorties beaucoup plus
longues.

*** TODO Pourquoi les sorties en C++ se mélangent-t-elle ? 

#+BEGIN_SRC sh :exports code
g++ -Wall -std=gnu++11 Codeparallelisme/startCpp.cpp -lpthread -o bin/startCpp
bin/startCpp
#+END_SRC

on obtient comme en C

: hello world! de 0
: hello world! de 1

mais aussi parfois

: hello world! de hello world! de 10
: 


et

: hello world! de hello world! de 0
: 1


** Démarrer des tasks en OpenMP

#+INCLUDE: Codeparallelisme/startOmp.c src C

#+BEGIN_SRC sh :exports code
gcc -Wall -fopenmp Codeparallelisme/startOmp.c -o bin/startOmp
bin/startOmp
#+END_SRC

La version OpenMP produit deux variantes:

: hello world! de 0
: hello world! de 1

et

: hello world! de 1
: hello world! de 0

** Démarrer des threads en Java

** Démarrer des threads en Cilk+

#+INCLUDE: Codeparallelisme/startCilk.c src C

#+BEGIN_SRC sh :exports code
gcc -Wall -std=gnu11 -fcilkplus Codeparallelisme/startCilk.c -o bin/startCilk
bin/startCilk
#+END_SRC


** Démarrer des go-routine en Go

** Démarrer des Tasks en Ada

** Démarrer des threads en D

** Démarrer des threads en Python

** Démarrer des threads en Ruby

** Le parallélisme en Perl


* Incrémenter une variable à plusieurs threads

** le problème en C

* La section critique
