Les architectures modernes sont capables de faire plusieurs opérations
simultanément de manière quasi-transparente pour le programmeur:
- avec l'exécution out-of-order des instructions du processeur
- en exécutant plusieurs flots d'instruction simultanément pour
  recouvrir les temps d'accès à la RAM ("l'hyperthreading" pour Intel)
- en faisant des calculs vectoriels (là les compilateurs ont encore
  des progrès à faire)

Ce parallélisme automatique est loin de refleter tout le potentiel
parallèle de la plupart des applications.  Les compilateurs ne sont
pas capable de l'extraire de manière automatique, même pour des
langages "simples" comme Fortran.

Le programmeur doit donc faire le travail d'expliquer au compilateur
et au matériel comment faire plusieurs choses à la fois.

* Comment lancer plusieurs activités partageant la même mémoire

  Dans la plupart des languages modernes, faire plusieurs choses à la
  fois dans le même espace de mémoire, i.e. dans le même processus, est
  souvent relativement facile à faire:
  - parce que c'est prévu dans le language: Go, Cilk, OpenMP, Ruby, Java
  - parce que c'est prévu dans la bibliothèque standard du langage: C,
    C++, D, Ada, Java, Perl, Python

  Cela n'a pas toujours été évident: il a fallu attendre la norme
  C-11, 40 ans après le début du langage, pour avoir des threads en C.
  
  En Java, l'interface intégrée au langage à l'origine était un peu
  trop simpliste. Une interface de type POSIX a été ensuite rajoutée
  dans la bibliothèque et complété avec de nombreuses fonctions de
  haut niveaux.

  Python et ruby, en collant aux opérateurs des langages compilés,
  atteignent pour l'instant un parallélisme limité. Perl, qui a pris
  un autre chemin, permet un parallélisme performant au prix d'une
  gymnastique intellectuelle différente des gymnastiques classiques.

*** Le programme "fil rouge"
  Les codes suivants réalisent plusieurs "hello world" en
  parallèle. Les exécutions ayant été réalisé sur un pocesseur
  Quad-core hyperthreadé, qui simule 8 coeurs sur quatre 4 physiques.
  Nous allons donc lancer 10 fois les même opérations, un peu plus que
  le nombre de coeurs HT, ce qui permet de voir des effets
  intéressants sur les exécutions.

  - Dix "Hello world" à la fois
  - Chaque thread attends 5 secondes avant de terminer

  Pour peaufiner la visualisation, le petit programme =perl= suivant,
  lit son entrée standart et affiche chaque ligne lue avec la date
  courante depuis son démarrage (en seconde)

#+INCLUDE: "./tempusfugit.pl" src perl

  Du coup, les programmes C, et assimilés, doivent forcer l'affichage
  immédiat (=fflush=) pour éviter tout délai dans le pipe séparant les
  programmes de celui marquant les dates d'apparitions des messages.

  On peut aussi utiliser le mono-ligne awk suivant, par exemple
#+BEGIN_SRC sh
./startC99 | awk 'BEGIN {i=systime();} {print systime()-i,$0}'
#+END_SRC

  Enfin, le programme =ts= de =moreutils= fait le travail 

#+BEGIN_SRC sh
./startC99 | ts -s "%s"
#+END_SRC


* Comment démarrer une activité ?

  Suivant les langages, le démarrage des threads sera plus ou moins
  intégré et facile. En gros il y a trois grandes familles de langages:
  
  - pas d'intégration :: [[POSIX threads en C]] donne un  aperçu
    de ce qui se passe dans le code de la plupart des autres
    implantations.
  - intégration dans la bibliothèque du langage :: Un /objet/ de type
       =Thread= permet la création des activités parallèles. Il n'y a
       pas d'interaction avec les autres opérateurs du langage.
  - intégration dans le langage :: Un /objet/ de type =Thread= qui
       interagit directement avec d'autres opérateurs du langage.
       [[Ada]], [[Java]]


* Comment attendre la fin des activités ?

* Dans quel ordre seront executée les activités ?
  
* L'affichage de petites lignes de texte ne pose aucun problème ?


** Points importants des exemples suivants
   Exécution: un core-i7 quad-core hyperthreadé
   - le multiplexage de l'accès au même fichier:
     - en C, on lance les threads qui affichent toujours dans le même
       ordre (très léger); contrairement à OpenMP dont l'ordre varie
       beaucoup (créations de tâches et des threads séparé)
     - en C++, contrairement à tous (?) les autres exemples, les sorties se
       mélangent: (stream != printf)
     - En Go il faut attendre explicitement la fin des go-routines, en
       OpenMP, ou en D, l'attente est implicite.


* Les différentes versions

** C-11
*** TODO Attendre la version de la glibc avec threads.h (C11)

** POSIX threads en C
   En pratique, la bibliothèque de threads implantée sous Linux est la
   bibliothèque POSIX. C'est elle qui est utilisé par la bibliothèque
   de C et de la quasi-totalité des autres languages.

#+INCLUDE: Codeparallelisme/startC99.c src C

ce qui après compilation et exécution

#+BEGIN_SRC sh :exports both
gcc -Wall -std=gnu99 Codeparallelisme/startC99.c -o bin/startC99 -lpthread
bin/startC99 | ts -s
#+END_SRC

produit l'affichage suivant

#+RESULTS:
| hello | world! | de | 2 |
| hello | world! | de | 5 |
| hello | world! | de | 6 |
| hello | world! | de | 4 |
| hello | world! | de | 1 |
| hello | world! | de | 0 |
| hello | world! | de | 8 |
| hello | world! | de | 7 |
| hello | world! | de | 3 |
| hello | world! | de | 9 |

** C++-11

#+INCLUDE: Codeparallelisme/startCpp.cpp src C++

La compilation et l'exécution sont intéressantes. Avec les iostream,
on a parfois des mélanges intéressants. Pour observer ce mélange en C
avec printf, il faudrait probablement des sorties beaucoup plus
longues.

*** TODO Pourquoi les sorties en C++ se mélangent-t-elle ? 

#+BEGIN_SRC sh :exports code
g++ -Wall -std=gnu++11 Codeparallelisme/startCpp.cpp -lpthread -o bin/startCpp
bin/startCpp
#+END_SRC

on obtient comme en C

: hello world! de 0
: hello world! de 1

mais aussi parfois

: hello world! de hello world! de 10
: 


et

: hello world! de hello world! de 0
: 1


** Démarrer des tasks en OpenMP

#+INCLUDE: Codeparallelisme/startOmp.c src C

#+BEGIN_SRC sh :exports code
gcc -Wall -fopenmp Codeparallelisme/startOmp.c -o bin/startOmp
bin/startOmp
#+END_SRC

La version OpenMP produit deux variantes:

: hello world! de 0
: hello world! de 1

et

: hello world! de 1
: hello world! de 0

** Démarrer des threads en Java
   
** Démarrer des threads en Cilk+

#+INCLUDE: Codeparallelisme/startCilk.c src C

#+BEGIN_SRC sh :exports code
gcc -Wall -std=gnu11 -fcilkplus Codeparallelisme/startCilk.c -o bin/startCilk
bin/startCilk
#+END_SRC

L'exécution en Cilk+ est très stable.

: hello world! de 0
: hello world! de 1


** Démarrer des go-routines en Go

#+INCLUDE: Codeparallelisme/startGo.go src go

Sans le channel pour la terminaison, le main et le processus termine
avant l'exécution des fonctions et l'on obtient aucun affichage.

#+BEGIN_SRC sh :exports code
go build -o -o bin/startGo Codeparallelisme/startGo.o 
bin/startGo
#+END_SRC

Une exécution très stable.

: Hello world! de  0
: Hello world! de  1

** Démarrer des Tasks en Ada

** Démarrer des threads en D

Une particularité importante est le fait que le main attende par défaut la
fin de tous les threads "spawnés" avant de terminer le processus.

#+INCLUDE: Codeparallelisme/startD.d src D


La compilation et le lancement
#+BEGIN_SRC sh :exports code
gdc -Wall -o ../bin/startD startD.d
bin/startD
#+END_SRC

donne systématiquement

: hello world! de 1
: hello world! de 0

** Démarrer des treads en Rust

#+INCLUDE: Codeparallelisme/startRust.rs src rust

La compilation et le lancement
#+BEGIN_SRC sh :exports both
rustc -O Codeparallelisme/startRust.rs -o bin/startRust
bin/startRust | ts -s
#+END_SRC

#+RESULTS:
| 00:00:00 | Hello | world | from | 6 |
| 00:00:00 | Hello | world | from | 0 |
| 00:00:00 | Hello | world | from | 3 |
| 00:00:00 | Hello | world | from | 7 |
| 00:00:00 | Hello | world | from | 2 |
| 00:00:00 | Hello | world | from | 5 |
| 00:00:00 | Hello | world | from | 4 |
| 00:00:00 | Hello | world | from | 1 |
| 00:00:00 | Hello | world | from | 8 |
| 00:00:00 | Hello | world | from | 9 |


** Démarrer des threads en Objective-C

** Démarrer des threads en Python
   

#+INCLUDE: Codeparallelisme/startPy.py src python

En python aussi une particularité importante est que le main attende la fin
des threads.

** Démarrer des threads en Ruby

** Le parallélisme en Perl


   
